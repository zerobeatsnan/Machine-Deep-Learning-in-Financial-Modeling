{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from copy import copy\n",
    "from tqdm import trange, tqdm\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import AssetPricing._auto_pca as ap\n",
    "from AssetPricing._auto_pca import StockDataset, Auto_PCA, custom_collate, negative_correlation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/boningzhou/kernel ipca/data/cha1.csv\", index_col=0)\n",
    "# data = pd.read_csv('D:/project/data/data.csv', index_col = 1)\n",
    "date = list(pd.unique(data.index))\n",
    "date.sort()\n",
    "ret = data.pivot(columns = 'PERMNO', values = 'RET').fillna(0).loc[date]\n",
    "\n",
    "characteristics = dict()\n",
    "for t in trange(len(date)):\n",
    "    key = date[t]\n",
    "    cha = data.loc[key].set_index('PERMNO').iloc[:, 1:]    \n",
    "    cha = 2*cha.rank()/cha.count()-1\n",
    "    rt = ret.loc[key, cha.index]\n",
    "    cha.loc[rt[rt == 0].index] = np.nan\n",
    "    cha = cha.dropna(how = 'all')\n",
    "    \n",
    "    characteristics[key] = cha\n",
    "\n",
    "ret[ret == 0] = np.nan\n",
    "ret = ret.add(- ret.mean(axis = 1), axis = 0).divide(ret.std(axis = 1), axis = 0)\n",
    "ret = ret.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train = date[:400]\n",
    "date_val = date[400:]\n",
    "ret_train = ret[:400]\n",
    "ret_val = ret[400:]\n",
    "characteristics_train = {k: characteristics[k] for k in date_train}\n",
    "characteristics_val = {k: characteristics[k] for k in date_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = StockDataset(characteristics_train, ret_train)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size = 1, collate_fn= custom_collate, shuffle = False)\n",
    "dataset_val = StockDataset(characteristics_val, ret_val)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size = 1, collate_fn= custom_collate, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_list = [36,1024,521,1]\n",
    "model = Auto_PCA(layer_list, sparsity_strength=1e-7, sparse_layer = 0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay = 1e-4)\n",
    "num_epoch = 100\n",
    "train_losses = []\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = StepLR(optimizer=optimizer, step_size=10, gamma = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "\n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    batch_count = 0\n",
    "    for i, (features_batch, labels_batch) in enumerate(tqdm(dataloader_train, desc = \"Batches\", leave = False)):\n",
    "        batch_losses = 0.0\n",
    "\n",
    "        for features, labels in zip(features_batch, labels_batch):\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "            size = output.shape[0]\n",
    "            output = output.squeeze()\n",
    "            # print(output.shape)\n",
    "            labels = labels.squeeze()\n",
    "            #labels = labels.unsqueeze(-1)\n",
    "            # print(labels.shape)\n",
    "            loss = negative_correlation_loss(output, labels) + model.sparsity_penalty()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses += loss.item()\n",
    "\n",
    "        training_loss += batch_losses\n",
    "        batch_count += 1\n",
    "\n",
    "\n",
    "    average_batch_loss = training_loss/batch_count\n",
    "    print(\"Epoch: {}, Training Loss: {}\".format(epoch, average_batch_loss))\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (features_batch, labels_batch) in enumerate(tqdm(dataloader_val, desc = \"Batches\", leave = False)):\n",
    "            batch_losses = 0.0\n",
    "\n",
    "            for features, labels in zip(features_batch, labels_batch):\n",
    "                features = features.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(features)\n",
    "                output = output.squeeze()\n",
    "                # print(output.shape)\n",
    "                labels = labels.squeeze()\n",
    "                #labels = labels.unsqueeze(-1)\n",
    "                # print(labels.shape)\n",
    "                loss = negative_correlation_loss(output, labels)\n",
    "                batch_losses += loss.item()\n",
    "\n",
    "            val_loss += batch_losses\n",
    "        average_val_loss = val_loss/batch_count\n",
    "        print(\"Epoch: {}, VAL Loss: {}\".format(epoch, average_val_loss))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
